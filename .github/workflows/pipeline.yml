name: Visit With Us Toursim Prediction Pipeline

on:
  push:
    branches:
      - main # Automatically triggers on push to the main branch
    paths:
      - 'Master/Data/tourism.csv'
      - 'Master/DataRegistration.py'
      - 'Master/DataPrepration.py'
      - 'Master/BuildingModels.py'
      - 'Master/main.py'
      - 'Master/HostingInHuggingFace.py'
      - '.github/workflows/pipeline.yml'
      - 'Master/Deployment/**'
  workflow_dispatch:

jobs:
  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Setup python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install huggingface_hub python-dotenv

      - name: List Directory Contents(Debug)
        run: |
          ls -la Master/Data/ || echo "Master/Data/ directory not found"
          ls -la . || echo "Root Directory contents"

      - name: Copy tourism.csv(if using a local file)
        run: |
          mkdir -p Master/Data
          if [ -f tourism.csv ]; then
            cp tourism.csv Master/Data/
            echo "Copied tourism.csv from root to Master/Data/"
          else
            echo "tourism.csv not found in root attemtpting to download from hugging face"

            python -c "from huggingface_hub import hf_hub_download;hf_hub_download(repo_id='jpkarthikeyan/Tourism-visit-with-us-dataset',filename='tourism.csv',local_dir='Master/Data/')"
            fi

      - name: Run Data Registration
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd Master
          python main.py --job register
        continue-on-error: false

      - name: Check Pipeline status
        if: failure()
        run: |
          echo "Data Registration pipeline failed. please check logs"
          exit 1

      - name: Verify Upload
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Verifying Upload on Hugging Face"
          python -c "import os;from huggingface_hub import HfApi;api= HfApi(token=os.getenv('HF_TOKEN'));print(api.repo_info(repo_id='jpkarthikeyan/Tourism-visit-with-us-dataset',repo_type='dataset'))"

  data-prepration:
    runs-on: ubuntu-latest
    needs: register-dataset
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy huggingface_hub python-dotenv datasets scikit-learn

      - name: Copying tourism.csv
        run: |
          mkdir -p Master/Data
          cp tourism.csv Master/Data || echo "tourism.csv not found in root"

      - name: Run DataPrepration.py
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd Master
          python main.py --job prepare
        continue-on-error: false

      - name: Check Pipeline Status
        if: failure()
        run: |
          echo "Data Prepration pipeline failed. please check the log"
          exit 1
      - name: Verify Upload
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Verifying Upload on Hugging Face"
          python -c "import os; from huggingface_hub import HfApi; token = os.getenv('HF_TOKEN');print(HfApi(token=token).repo_info(repo_id='jpkarthikeyan/Tourism-visit-with-us-dataset', repo_type='dataset'))"

  model-building:
    runs-on: ubuntu-latest
    needs: data-prepration
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install huggingface_hub python-dotenv pandas numpy scikit-learn joblib xgboost seaborn matplotlib datasets mlflow

      - name: Create Model Dump Directory
        run: |
          mkdir -p Master/Model_Dump_JOBLIB
          mkdir -p Master/mlruns
      - name: Set Permission for MLFlow and Model Directories
        run: |
          mkdir -p Master/mlruns && chmod -R 777 Master/mlruns
          mkdir -p Master/Model_Dump_JOBLIB && chmod -R 777 Master/Model_Dump_JOBLIB

      - name: Run Model Building
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          MLFLOW_TRACKING_URI: file://${{ github.workspace }}/Master/mlruns
        run: |
          cd Master
          python main.py --job modelbuilding
        continue-on-error: false

      - name: Check pipeline status
        if: failure()
        run: |
          echo "Exception in Build Models. please check logs"
          exit 1

      - name: Verify Execution
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Verifying the execution"
          python -c "import os; from huggingface_hub import HfApi;token=os.getenv('HF_TOKEN');print(HfApi(token=token).repo_info(repo_id='jpkarthikeyan/Tourism_Prediction_Model',repo_type='model')) "

      - name: List Generated Files
        run: |
          ls -l Master/Model_Dump_JOBLIB/



      - name: Commit and Push Generated Files
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add Master/Model_Dump_JOBLIB/*
          git commit -m "Adding genearated model files and confusion matrix plots" || echo "No changes to commit"

          git pull origin main --rebase || {
             echo "Merge Conflict detectd. Aborting rebase and skipping"
             git rebase --abort
             exit 0
             }

          git pull origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Handle Rebase Failure
        if: failure()
        run:
          echo "Rebase failed. cleaning up"
          git rebase --abort || true
          exit 0


  deploy-to-spaces:
    runs-on: ubuntu-latest
    permissions:
      packages: write
      contents: read
      actions: read
    needs: model-building
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: SET UP PYTHON
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: INSTALL DEPENDENCIES
        run: |
          python -m pip install --upgrade pip
          pip install huggingface_hub python-dotenv

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Debug Authentication
        run: |
          echo "Actor: $GITHUB_ACTOR"
          echo "PAT_TOKEN is set: ${PAT_TOKEN:+[SET_${#PAT_TOKEN}_chars]}"
          if [ -z "$PAT_TOKEN" ]; then
            echo "PAT_TOKEN is empty";
          else
            echo "PAT_TOKEN length: ${#PAT_TOKEN}";
          fi

      - name: Login to GITHUB CONTAINER REGISTRY
        env:
          PAT_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          echo "Login to GITHUB Container Reistry"
          echo $PAT_TOKEN | docker login -u ${GITHUB_ACTOR} --password-stdin ghcr.io
          echo "Docker Login succss"

      - name: Build and Push Docker image to GITHUB Container REGISTRY
        env:
          PAT_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          cd Master/Deployment
          docker build -t jpkarthik/tourism-prediction-app:latest .
          docker tag jpkarthik/tourism-prediction-app:latest ghcr.io/jpkarthik/tourism-prediction-app:latest
          docker push ghcr.io/jpkarthik/tourism-prediction-app:latest

      - name: Deploy to Hugging Face Spaces
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd Master
          python main.py --job deploy
          echo "Deployment To HF Space"


      - name: Check Deployment Status
        if: failure()
        run: |
          echo "Deployment to Huggingface space failed please check logs"
          exit 1
