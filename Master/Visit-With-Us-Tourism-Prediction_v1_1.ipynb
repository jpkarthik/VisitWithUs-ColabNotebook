{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["K7HT7f_W63Q9","gaE_eACI7Wdl"],"mount_file_id":"11jhgihTvfEl_lQBJdTK_BRuURY6lfv_Q","authorship_tag":"ABX9TyMlOQrQ/zEbgkLIv5TwrwWn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1010878b0b20487b825d45ddd2caf18e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76bab99c6e914e7c858d227ed36004fe","IPY_MODEL_8ef10607646f4c4188df8a0d3087faaa","IPY_MODEL_a98c4c656420419f94e490a6aeb2f51e"],"layout":"IPY_MODEL_9356b1fd50944ad79b79f164e72ac40c"}},"76bab99c6e914e7c858d227ed36004fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96893e11a10149959294246b255862d8","placeholder":"​","style":"IPY_MODEL_f929fd25df6742afa80ceada1ab8f345","value":"BestModel_XGBoostingClassifier.joblib: 100%"}},"8ef10607646f4c4188df8a0d3087faaa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b481b0548514e9d8bf745acc896361f","max":271670,"min":0,"orientation":"horizontal","style":"IPY_MODEL_529758d5fcc74c05a5a5e837d4b336c9","value":271670}},"a98c4c656420419f94e490a6aeb2f51e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06e3c95bfed14fe9a05e45a49d1419a1","placeholder":"​","style":"IPY_MODEL_f50146a937ce436988d9fb8157741336","value":" 272k/272k [00:00&lt;00:00, 416kB/s]"}},"9356b1fd50944ad79b79f164e72ac40c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96893e11a10149959294246b255862d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f929fd25df6742afa80ceada1ab8f345":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b481b0548514e9d8bf745acc896361f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"529758d5fcc74c05a5a5e837d4b336c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06e3c95bfed14fe9a05e45a49d1419a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f50146a937ce436988d9fb8157741336":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Project Folder Structure"],"metadata":{"id":"K7HT7f_W63Q9"}},{"cell_type":"markdown","source":["Project Folder Structure\n","\n","|->`Drive`/VisitWithUs-Tourism\n","\n","  |->Master\n","  \n","    |->Data\n","        |->tourism.csv\n","        |->train.csv\n","        |->test.csv\n","    |->Deployment\n","        |->app.py\n","        |->Dockerfile\n","        |->README.md\n","        |->requirements.txt\n","    |->Model_Building\n","        |->BuildingModels.py\n","        |->DataPrepration.py\n","        |->DataRegistration.py\n","    |->Model_Dump_JOBLIB\n","        |->best_threshold.txt\n","        |->BestModel_XGBoostingClassifier.joblib\n","    |->pipeline.yml\n","  |->AIML_MLOPS_v1_1.ipynb"],"metadata":{"id":"FMxBY8Nqd0ve"}},{"cell_type":"markdown","source":["# Loading Packages"],"metadata":{"id":"gaE_eACI7Wdl"}},{"cell_type":"code","source":["!pip install huggingface_hub\n","!pip install python-dotenv\n","!pip install datasets\n","!pip install pandas\n","!pip install scikit-learn\n","!pip install xgboost\n","!pip install seaborn\n","!pip install matplotlib\n","!pip install joblib\n","!pip install stramlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zzL9Lcv7HHX","outputId":"1548a24b-fe97-40f3-8a61-518bc4c8e93e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.34.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.8.3)\n"]}]},{"cell_type":"markdown","source":["# MOUNTING DRIVE"],"metadata":{"id":"ognKAWMS8G_j"}},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd '/content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master/'\n","base_path = os.getcwd()\n","print(f\"Base Path {base_path}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vw9tngctf_m5","executionInfo":{"status":"ok","timestamp":1755311547941,"user_tz":-330,"elapsed":2060,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"7942853d-6644-44a8-8701-181b08d4ff0d"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master\n","Base Path /content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master\n"]}]},{"cell_type":"code","source":["from google.colab import userdata\n","hf_token = userdata.get('HF_TOKEN')"],"metadata":{"id":"aWq8odPlk7Jk","executionInfo":{"status":"ok","timestamp":1755311569045,"user_tz":-330,"elapsed":594,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["# 1. DATA REGISTRATION"],"metadata":{"id":"UQ_4lbVH0fTI"}},{"cell_type":"code","source":["#@title Data Registration Class\n","%%writefile DataRegistration.py\n","import os\n","import traceback\n","import inspect\n","from huggingface_hub import HfApi, create_repo,login,hf_hub_download\n","\n","class DataRegistration:\n","  def __init__(self,base_path,hf_token=None):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    self.repoID = 'jpkarthikeyan/Tourism-visit-with-us-dataset'\n","    self.Subfolders = os.path.join(base_path,'Data')\n","    self.folder_Master = base_path\n","    self.folder_data = os.path.join(base_path,\"Data\")\n","    self.hf_token = hf_token\n","    print(f\"self.hf_token: {self.hf_token}\")\n","    os.makedirs(self.folder_data, exist_ok=True)\n","    print(f\"self.Subfolders: {self.Subfolders}\")\n","    print(f\"self.folder_Master: {self.folder_Master}\")\n","    print(f\"folder_data: {self.folder_data}\")\n","    print('-'*50)\n","\n","  def HFCreateRepo(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      api = HfApi(token=self.hf_token)\n","      create_repo(repo_id=self.repoID,\n","                  private=False,\n","                  repo_type='dataset',\n","                  exist_ok=True)\n","      print(f\"Repo {self.repoID} created\")\n","      return True\n","\n","    except Exception as ex:\n","      if hasattr(ex,'response') and ex.response.status_code == 409:\n","        print(f\"Repo {self.repoID} already exists\")\n","        return True\n","      else:\n","        print(f\"Exception {ex}\")\n","        traceback.print_exc()\n","        return False\n","    finally:\n","      print(\"-\"*100)\n","\n","\n","  def UploadingSourceData(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      source_data_file = os.path.join(self.folder_data,'tourism.csv')\n","      print(f\"Soruce Data File {source_data_file}\")\n","      if not os.path.exists(source_data_file):\n","        raise FileNotFoundError(f\"File {source_data_file} not found\")\n","      api = HfApi()\n","      api.upload_file(\n","          path_or_fileobj = source_data_file,\n","          path_in_repo = 'Master/Data/tourism.csv',\n","          repo_id = self.repoID,\n","          repo_type='dataset',\n","          token=self.hf_token)\n","      print(f\"Source data tourism.csv uploaded into {self.repoID}\")\n","      return True\n","\n","    except Exception as ex:\n","       print(f\"Exception at {inspect.currentframe().f_code.co_name} Exception: {ex}\")\n","       traceback.print_exc()\n","       return False\n","    finally:\n","      print(\"-\"*100)\n","\n","  def ToRunPipeline(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    if not self.HFCreateRepo():\n","      print('Exception in data registration HFCreateRepo')\n","      return False\n","    else:\n","      print('-'*50)\n","      if not self.UploadingSourceData():\n","        print('Exception in data registration UploadingSourceData')\n","        return False\n","      else:\n","        print('Data Registration Completed')\n","        print('-'*50)\n","        return True"],"metadata":{"id":"nDUqHrVl0q7o","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755307906180,"user_tz":-330,"elapsed":72,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"bc1ef5f0-cac1-4eef-cb69-2eb89d39b077"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting DataRegistration.py\n"]}]},{"cell_type":"code","source":["dataRegObj = DataRegistration(base_path,hf_token)\n","if dataRegObj.ToRunPipeline():\n","  print('Success: Data Registration in hugging face completed')\n","else:\n","  print('Exception: Data Registration in Hugging Face failed')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2CX2TxkZo-0","executionInfo":{"status":"ok","timestamp":1755307913380,"user_tz":-330,"elapsed":1320,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"60cb0535-f8f8-4e5c-ca0f-30fd71f0e255"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Function Name __init__\n","self.hf_token: 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\n","self.Subfolders: /content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master/Data\n","self.folder_Master: /content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master\n","folder_data: /content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master/Data\n","Function Name ToRunPipeline\n","Function Name HFCreateRepo\n","Repo jpkarthikeyan/Tourism-visit-with-us-dataset created\n","----------------------------------------------------------------------------------------------------\n","Function Name UploadingSourceData\n","Soruce Data File /content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master/Data/tourism.csv\n","Source data tourism.csv uploaded into jpkarthikeyan/Tourism-visit-with-us-dataset\n","----------------------------------------------------------------------------------------------------\n","Data Registration Completed\n","Success: Data Registration in hugging face completed\n"]}]},{"cell_type":"markdown","source":["# 2. Data Prepration"],"metadata":{"id":"2XxU9ZdG-DE9"}},{"cell_type":"code","source":["#@title DataPrepration.py\n","%%writefile DataPrepration.py\n","import os\n","import pandas as pd\n","import inspect\n","import traceback\n","from datasets import load_dataset\n","from sklearn.model_selection import train_test_split\n","from huggingface_hub import HfApi, create_repo, login, hf_hub_download\n","\n","class DataPrepration:\n","  def __init__(self,base_path, hf_token=None):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    self.repoID = 'jpkarthikeyan/Tourism-visit-with-us-dataset'\n","    self.Subfolders = os.path.join(base_path, 'Data')\n","    self.hf_token = hf_token\n","    print(f'self.repoID: {self.repoID}')\n","    print(f'self.Subfolders: {self.Subfolders}')\n","    print('-'*50)\n","\n","  def LoadDatasetFromHF(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      df_dataset = pd.read_csv(hf_hub_download(\n","                                repo_id = self.repoID,\n","                                filename = 'Master/Data/tourism.csv',\n","                                repo_type='dataset'\n","                              ))\n","\n","      print(f'Shape of the original dataset {df_dataset.shape}')\n","\n","      if 'Unnamed: 0' in df_dataset.columns:\n","        df_dataset = df_dataset.drop(['Unnamed: 0'],axis=1)\n","\n","      print(f\"Dataset loaded from {self.repoID}/{self.Subfolders}\")\n","      print(f\"Shape of the Original Dataset: {df_dataset.shape}\")\n","      return df_dataset\n","    except Exception as ex:\n","      print(f\"Exception {ex}\")\n","      traceback.print_exc()\n","      return None\n","    finally:\n","      print('-'*50)\n","\n","  def TrainTestSplit(self,df_dataset):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      print(f\"Value Count {df_dataset['ProdTaken'].value_counts()}\")\n","\n","      df_train,df_test = train_test_split(df_dataset,\n","                                          test_size=0.2,\n","                                          random_state=42,\n","                                          stratify=df_dataset['ProdTaken'],\n","                                          shuffle=True)\n","\n","      print(f\"Shape of the train dataset: {df_train.shape}\")\n","      print(f\"Shape of the test dataset: {df_test.shape}\")\n","\n","      return df_train, df_test\n","    except Exception as ex:\n","      print(f'Exception: {ex}')\n","      print(traceback.print_exc())\n","      return None, None\n","    finally:\n","      print('-'*50)\n","\n","  def DatasetCleaning(self,df_data):\n","    try:\n","      print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","      df_data['Gender'] = df_data['Gender'].replace('Fe Male', 'Female')\n","\n","      df_data = df_data.drop_duplicates(subset=['CustomerID'], keep='first').reset_index(drop=True)\n","\n","      for clmn in df_data.columns:\n","        if df_data[clmn].dtype in ['int64']:\n","          #print(f\"{clmn} replacing the missing value with median\")\n","          df_data[clmn] = df_data[clmn].fillna(df_data[clmn].median())\n","        else:\n","          #print(f\"{clmn} replacing the missing value with mode\")\n","          df_data[clmn] = df_data[clmn].fillna(df_data[clmn].mode()[0])\n","\n","      df_data = df_data.drop(['CustomerID'], axis=1)\n","\n","      numerical_column = df_data.select_dtypes(include=['int64'])\n","\n","      for num_col in numerical_column:\n","        Q1 = df_data[num_col].quantile(0.25)\n","        Q3 = df_data[num_col].quantile(0.75)\n","        IQR = Q3 - Q1\n","        lower = Q1 - 1.5*IQR\n","        upper = Q3 + 1.5*IQR\n","        #df_data[num_col] = df_data[num_col].clip(lower,upper)\n","\n","      return df_data\n","\n","    except Exception as ex:\n","      print(f\"Exception {ex}\")\n","      print(traceback.print_exc())\n","      return None\n","    finally:\n","      print('-'*50)\n","\n","  def UploadIntoHF(self,df,drive_path,file_name):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      file_path = os.path.join(drive_path,file_name)\n","      df.to_csv(file_path,index=False)\n","\n","      api = HfApi(token = self.hf_token)\n","      api.upload_file(path_or_fileobj =file_path,\n","                      path_in_repo= f\"Master/Data/{file_name}\",\n","                      repo_id = self.repoID,\n","                      repo_type='dataset',\n","                      token=self.hf_token)\n","      print(f\"Source data {file_name} uploaded into {self.repoID}\")\n","      return True\n","    except Exception as ex:\n","      print(f\"Exception: {ex}\")\n","      traceback.print_exc()\n","      return False\n","    finally:\n","      print('-'*50)\n","\n","  def ToRunPipeline(self):\n","    try:\n","      print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","      df_dataset = self.LoadDatasetFromHF()\n","      if df_dataset is None:\n","        return False\n","      else:\n","        df_train, df_test = self.TrainTestSplit(df_dataset)\n","        if df_train is None or df_test is None:\n","          return False\n","        else:\n","          df_train_cleaned = self.DatasetCleaning(df_train)\n","          df_test_cleaned = self.DatasetCleaning(df_test)\n","          if df_train is None or df_test is None:\n","            return False\n","          else:\n","            result_train = self.UploadIntoHF(df_train_cleaned,\n","                                             self.Subfolders,'train.csv')\n","            result_test = self.UploadIntoHF(df_test_cleaned,\n","                                            self.Subfolders,'test.csv')\n","            if not result_train or not result_test:\n","              print('Splitted dataset upload into HF Exception')\n","              return False\n","            else:\n","              print('Dataset downloaded from HF, Cleaned, Splitted into train and test dataset and uploaded back into HF dataset')\n","              return True\n","    except Exception as ex:\n","      print(f\"Exception message in ToRunPipeline: {ex}\")\n","      traceback.print_exc()\n","      return False\n","    finally:\n","      print('-'*50)"],"metadata":{"id":"aFDYFew4-GjR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755307921285,"user_tz":-330,"elapsed":25,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"47571e7d-236e-4cd9-c400-9eda3b4be6b0"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting DataPrepration.py\n"]}]},{"cell_type":"code","source":["ObjDataPrep = DataPrepration(base_path,hf_token)\n","if ObjDataPrep.ToRunPipeline():\n","  print('Success: Data Prepration Completed')\n","else:\n","  print('Exception: Data prepration failed')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"767FZUN7etS1","executionInfo":{"status":"ok","timestamp":1755307933957,"user_tz":-330,"elapsed":1723,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"9579dae1-69e9-4f50-dbf7-8fa5be024843"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Function Name __init__\n","self.repoID: jpkarthikeyan/Tourism-visit-with-us-dataset\n","self.Subfolders: /content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master/Data\n","--------------------------------------------------\n","Function Name ToRunPipeline\n","Function Name LoadDatasetFromHF\n","Shape of the original dataset (4128, 21)\n","Dataset loaded from jpkarthikeyan/Tourism-visit-with-us-dataset//content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master/Data\n","Shape of the Original Dataset: (4128, 20)\n","--------------------------------------------------\n","Function Name TrainTestSplit\n","Value Count ProdTaken\n","0    3331\n","1     797\n","Name: count, dtype: int64\n","Shape of the train dataset: (3302, 20)\n","Shape of the test dataset: (826, 20)\n","--------------------------------------------------\n","Function Name DatasetCleaning\n","--------------------------------------------------\n","Function Name DatasetCleaning\n","--------------------------------------------------\n","Function Name UploadIntoHF\n","Source data train.csv uploaded into jpkarthikeyan/Tourism-visit-with-us-dataset\n","--------------------------------------------------\n","Function Name UploadIntoHF\n","Source data test.csv uploaded into jpkarthikeyan/Tourism-visit-with-us-dataset\n","--------------------------------------------------\n","Dataset downloaded from HF, Cleaned, Splitted into train and test dataset and uploaded back into HF dataset\n","--------------------------------------------------\n","Success: Data Prepration Completed\n"]}]},{"cell_type":"markdown","source":["# 3.Model Building with Experimentation Tracking"],"metadata":{"id":"vpSiNqjnWIf_"}},{"cell_type":"code","source":["#@title BuildingModels.py\n","%%writefile BuildingModels.py\n","\n","import os\n","import joblib\n","import inspect\n","import traceback\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from xgboost import XGBClassifier\n","from datasets import load_dataset\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.impute import SimpleImputer\n","from huggingface_hub.utils import RepositoryNotFoundError\n","from huggingface_hub import HfApi, create_repo, login\n","from huggingface_hub import hf_hub_download\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.model_selection import KFold, RandomizedSearchCV\n","from sklearn.metrics import precision_recall_curve, precision_score\n","from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n","from sklearn.metrics import recall_score, f1_score, classification_report\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","\n","class BuildingModels:\n","  def __init__(self,base_path, hf_token=None):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    self.models = {}\n","    self.best_model = None\n","    self.best_score = 0\n","    self.best_f1_score =0.0\n","    self.best_model_threshold = 0.0\n","    self.best_model_name=None\n","    self.df_train = pd.DataFrame()\n","    self.df_test = pd.DataFrame()\n","    self.feature_train = pd.DataFrame()\n","    self.feature_test = pd.DataFrame()\n","    self.target_train = pd.Series()\n","    self.target_test = pd.Series()\n","    self.base_path = base_path\n","    self.Subfolders = os.path.join(base_path,'data')\n","    self.repo_id = 'jpkarthikeyan/Tourism_Prediction_Model'\n","    self.ds_repo_id = 'jpkarthikeyan/Tourism-visit-with-us-dataset'\n","    self.repo_type = 'model'\n","    self.hf_token = hf_token\n","    self.categorical_columns = ['TypeofContact','Occupation','Gender','ProductPitched','MaritalStatus','Designation']\n","    self.numerical_columns = ['Age','CityTier','DurationOfPitch','NumberOfPersonVisiting',\n","                              'NumberOfFollowups','PreferredPropertyStar',\n","                              'NumberOfTrips','Passport','PitchSatisfactionScore','OwnCar',\n","                              'NumberOfChildrenVisiting','MonthlyIncome']\n","\n","    self.pipeline_numerical = Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='median')),\n","        ('scaler', StandardScaler())\n","    ])\n","\n","    self.pipeline_onehot = Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='most_frequent')),\n","        ('onehot', OneHotEncoder(drop='first',handle_unknown='ignore',sparse_output=False))\n","    ])\n","\n","  def Load_data_from_HF(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      print(f'Loading the train dataset from {self.ds_repo_id}')\n","\n","      self.df_train = pd.read_csv(hf_hub_download(\n","                                repo_id = self.ds_repo_id,\n","                                filename = 'Master/Data/train.csv',repo_type='dataset'))\n","      self.df_test = pd.read_csv(hf_hub_download(\n","                                repo_id = self.ds_repo_id,\n","                                filename = 'Master/Data/test.csv',repo_type='dataset'))\n","      print(f\"Shape of the train dataset: {self.df_train.shape}\")\n","      print(f\"Shape of the train dataset: {self.df_test.shape}\")\n","\n","      return True\n","    except Exception as ex:\n","      print(f\"Exception: {ex}\")\n","      traceback.print_exc()\n","      return False\n","    finally:\n","      print('-'*50)\n","\n","  def Preprocessing_dataset(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","\n","      self.target_train = self.df_train['ProdTaken']\n","      self.feature_train = self.df_train.drop(['ProdTaken'],axis=1)\n","\n","      self.target_test = self.df_test['ProdTaken']\n","      self.feature_test = self.df_test.drop(['ProdTaken'],axis=1)\n","\n","      return True\n","\n","    except Exception as ex:\n","      print(f\"Exception: {ex}\")\n","      traceback.print_exc()\n","      return False\n","    finally:\n","      print('-'*50)\n","\n","  def Building_Models(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      preprocessor = ColumnTransformer(\n","          transformers=[\n","              ('num', self.pipeline_numerical,self.numerical_columns),\n","              ('onehot', OneHotEncoder(drop='first',handle_unknown='ignore',\n","                        sparse_output=False),self.categorical_columns)])\n","      models_params = {\n","          'DecisionTreeClassifier':{\n","              'model': DecisionTreeClassifier(class_weight='balanced',random_state=42),\n","              'params': {'classifier__criterion':['gini','entropy'],\n","                         'classifier__splitter':['best','random'],\n","                        'classifier__max_depth':[1],\n","                         'classifier__min_samples_leaf':[1,2,4],\n","                         'classifier__min_samples_split':[2,5,10],\n","                         'classifier__max_features':['sqrt','log2',None]}\n","          },\n","\n","          'RandomForestClassifier':{\n","              'model': RandomForestClassifier(class_weight='balanced',random_state=42),\n","              'params': { 'classifier__n_estimators':[25,50,75,100],\n","                          'classifier__criterion':['gini','entropy'],\n","                          'classifier__max_depth':[5,10,15],\n","                          'classifier__min_samples_split':[15,20,25],\n","                          'classifier__min_samples_leaf':[7,10,15],\n","                          'classifier__max_features':[0.3,0.5,0.6],\n","                          'classifier__oob_score':[True],\n","                          'classifier__bootstrap':[True]\n","                         }\n","          },\n","\n","          'BaggingClassifier':{\n","              'model': BaggingClassifier(estimator=DecisionTreeClassifier(class_weight='balanced',random_state=42)),\n","              'params':{  'classifier__n_estimators':[10,50,75,100],\n","                          'classifier__max_samples':[0.3,0.5,0.7,0.9],\n","                          'classifier__max_features':[0.3,0.5,0.7],\n","                          'classifier__oob_score':[True],\n","                          'classifier__estimator__criterion':['gini','entropy'],\n","                          'classifier__estimator__max_depth':[5,7,9],\n","                          'classifier__estimator__min_samples_split':[8,10,12],\n","                          'classifier__estimator__min_samples_leaf':[2,3,5]\n","                        }\n","          },\n","\n","          'AdaBoostingClassifier':{\n","              'model': AdaBoostClassifier(random_state=42),\n","              'params':{  'classifier__n_estimators':[50,75,100],\n","                          'classifier__learning_rate':[0.01,0.05,0.1],\n","                          'classifier__algorithm':['SAMME','SAMME.R']\n","\n","                      }\n","          },\n","\n","          'GradientBoostingClassifier':{\n","              'model': GradientBoostingClassifier(random_state=42),\n","              'params':{\n","                          'classifier__n_estimators':[50,75,100,125],\n","                          'classifier__learning_rate':[0.01,0.5,0.1],\n","                          'classifier__criterion':['friedman_mse','squared_error'],\n","                          'classifier__max_features':['sqrt','log2'],\n","                          'classifier__min_samples_leaf':[1,2,4],\n","                          'classifier__subsample':[0.6,0.7,0.8],\n","                          'classifier__max_depth':[2,3,4,5]\n","                        }\n","          },\n","\n","          'XGBoostingClassifier':{\n","              'model':XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n","              'params':{'classifier__n_estimators':np.arange(50,100,10),\n","                        'classifier__max_depth': [3,5,7],\n","                        'classifier__learning_rate':[0.01,0.1,0.2],\n","                        'classifier__subsample':[0.6,0.8,1.0],\n","                        'classifier__colsample_bytree':[0.6,0.8,1.0],\n","                        'classifier__gamma':[0,1,2],\n","                        'classifier__reg_alpha':[0,1,2]\n","\n","                        }\n","          }\n","\n","        }\n","\n","      cv_KFold = KFold(n_splits=3,random_state=42,shuffle=True)\n","\n","      for model_name, mdl_params in models_params.items():\n","        print(f'Model {model_name} started')\n","        pipeline = Pipeline(steps=[\n","            ('preprocessor',preprocessor),\n","            ('classifier',mdl_params['model'])\n","        ])\n","        random_search = RandomizedSearchCV(pipeline,mdl_params['params'],\n","                                           n_iter=50,cv=cv_KFold,scoring='f1',\n","                                           random_state=42,n_jobs=-1,verbose=2)\n","\n","        random_search.fit(self.feature_train,self.target_train)\n","\n","        self.models[model_name] = {\n","            'model':random_search.best_estimator_,\n","            'best_score': random_search.best_score_,\n","            'best_params':random_search.best_params_\n","        }\n","        joblib.dump(random_search.best_estimator_,f'{self.base_path}/Model_Dump_JOBLIB/{model_name}.joblib')\n","        print(f'model:{random_search.best_estimator_}')\n","        print(f'best_score: {random_search.best_score_}')\n","        print(f'best_params: {random_search.best_params_}')\n","        print(f'Modle {model_name} completed')\n","        print('-'*50)\n","\n","      return self.models\n","    except Exception as ex:\n","      print(f\"Exception: {ex}\")\n","    finally:\n","      print('-'*50)\n","\n","  def Model_Evaluation(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    df_metrics = pd.DataFrame()\n","    try:\n","      for mdl_name, mdl_info in self.models.items():\n","        model = mdl_info['model']\n","        predict_proability = model.predict_proba(self.feature_test)\n","        print(f\"Predict proability shape {mdl_name} {predict_proability.shape}\")\n","        if predict_proability.shape[1] ==1:\n","          predict_proability = predict_proability.flatten()\n","        else:\n","          predict_proability = predict_proability[:,1]\n","\n","\n","        prc_precision,prc_recall, prc_threshold = precision_recall_curve(self.target_test,predict_proability)\n","        prc_f1score = 2*((prc_precision*prc_recall) / (prc_precision+prc_recall+1e-10))\n","\n","        prc_threshold_idmx = np.argmax(prc_f1score)\n","        prc_best_threshold = prc_threshold[prc_threshold_idmx]\n","        print(f'best threshold: {prc_best_threshold}')\n","\n","        predic_prob_threshold = (predict_proability >= prc_best_threshold).astype(int)\n","        #predic_prob_threshold = (predict_proability >= 0.5).astype(int)\n","        accuracy = accuracy_score(self.target_test,predic_prob_threshold)\n","        precision = precision_score(self.target_test,predic_prob_threshold)\n","        recall = recall_score(self.target_test,predic_prob_threshold)\n","        f1score = f1_score(self.target_test,predic_prob_threshold)\n","        class_report = classification_report(self.target_test,predic_prob_threshold)\n","        conf_matrix = confusion_matrix(self.target_test,predic_prob_threshold)\n","\n","        lbl = ['TN', 'FP', 'FN', 'TP']\n","        cnf_lbl = ['\\n{0:0.0f}'.format(cnf_val) for cnf_val in conf_matrix.flatten()]\n","        cn_percentage = [\"\\n{0:.2%}\".format(item/conf_matrix.flatten().sum()) for item in conf_matrix.flatten()]\n","\n","        confusion_label = np.asarray([[\"\\n {0:0.0f}\".format(item)+\"\\n{0:.2%}\".format(item/conf_matrix.flatten().sum())]\n","                                for item in conf_matrix.flatten()]).reshape(2,2)\n","\n","        cnf_label = np.asarray([f'{lbl1} {lbl2} {lbl3}' for lbl1, lbl2, lbl3 in zip(lbl, cnf_lbl,  cn_percentage)]).reshape(2,2)\n","\n","        plt.figure(figsize = (3,3))\n","        sns.heatmap(conf_matrix, annot = cnf_label, cmap = 'Spectral', fmt='' )\n","        plt.xlabel('Predicted')\n","        plt.ylabel('Actual')\n","        plt.title(f'{mdl_name} confusion matrix')\n","        plt.tight_layout()\n","        plt.show()\n","        plot_path = os.path.join(self.base_path,'Model_Dump_JOBLIB',f'{mdl_name}_ConfusionMatrix.png')\n","        plt.savefig(plot_path)\n","        plt.close()\n","\n","\n","        df_metrics = pd.concat([df_metrics,pd.DataFrame({'model':[mdl_name],'accuracy':[accuracy],\n","                                            'precision':[precision], 'recall':[recall],\n","                                            'f1_score':[f1score]})],ignore_index=True)\n","\n","        if f1score > self.best_f1_score:\n","          self.best_f1_score = f1score\n","          self.best_model_threshold = prc_best_threshold\n","          self.best_model_name = mdl_name\n","\n","      best_model = self.models[self.best_model_name]['model']\n","      if hasattr(best_model, 'feature_importances_'):\n","        feature_importance = pd.DataFrame({\n","            'feature':self.feature_train.columns,\n","            'importance': best_model.feature_importances_\n","        }).sort_values('importance',ascending=False)\n","        print('Feature Importance:\\n',feature_importance)\n","\n","\n","      return df_metrics\n","\n","    except Exception as ex:\n","      print(f\"Exception: {ex}\")\n","    finally:\n","      print('-'*50)\n","\n","  def Register_BestModel_HF(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      best_model = self.models[self.best_model_name]['model']\n","      joblib.dump(best_model,f'{self.base_path}/Model_Dump_JOBLIB/BestModel_{self.best_model_name}.joblib')\n","\n","\n","      api = HfApi()\n","      try:\n","        api.repo_info(repo_id=self.repo_id,repo_type=self.repo_type)\n","      except RepositoryNotFoundError:\n","        api.create_repo(repo_id=self.repo_id, repo_type=self.repo_type,private=False)\n","\n","\n","      print(\"Uploading the best model into Hugging face\")\n","      api.upload_file(path_or_fileobj = f'{self.base_path}/Model_Dump_JOBLIB/BestModel_{self.best_model_name}.joblib',\n","                      path_in_repo = f\"Model_Dump_JOBLIB/BestModel_{self.best_model_name}.joblib\",\n","                      repo_id=self.repo_id, repo_type=self.repo_type\n","                      )\n","\n","\n","      print(\"Uploading the best threshold text file to HF\")\n","      with open(f'{self.base_path}/Model_Dump_JOBLIB/best_threshold.txt','w') as f:\n","        f.write(str(self.best_model_threshold))\n","      api.upload_file(path_or_fileobj = f\"{self.base_path}/Model_Dump_JOBLIB/best_threshold.txt\",\n","                      path_in_repo = f\"Model_Dump_JOBLIB/best_threshold.txt\",\n","                      repo_id=self.repo_id, repo_type=self.repo_type\n","                      )\n","\n","      return True\n","\n","\n","    except Exception as ex:\n","      print(f\"Exception: {ex}\")\n","      traceback.print_exc()\n","      return False\n","    finally:\n","      print('-'*50)\n","\n","  def ToRunPipeline(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      if not self.Load_data_from_HF():\n","        return False\n","      else:\n","        if not self.Preprocessing_dataset():\n","          return False\n","        else:\n","          Build_Model = self.Building_Models()\n","          print(Build_Model)\n","          if Build_Model:\n","            df_Metrics = self.Model_Evaluation()\n","            print(df_Metrics)\n","            if not df_Metrics.empty:\n","              if self.Register_BestModel_HF():\n","                return True\n","              else:\n","                return False\n","            else:\n","              return False\n","          else:\n","            return False\n","    except Exception as ex:\n","      print(f'Exception occured {ex}')\n","    finally:\n","      print('-'*50)\n"],"metadata":{"id":"Og90ls1JWWto","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755310728962,"user_tz":-330,"elapsed":79,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"3253fc78-3199-40ed-dc78-b39334d60b66"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting BuildingModels.py\n"]}]},{"cell_type":"code","source":["ObjModelBuild = BuildingModels(base_path,hf_token)\n","if ObjModelBuild.ToRunPipeline():\n","  print('Success: BuildingModels.py Completed')\n","else:\n","  print('Exception: BuildingModels.py failed')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1010878b0b20487b825d45ddd2caf18e","76bab99c6e914e7c858d227ed36004fe","8ef10607646f4c4188df8a0d3087faaa","a98c4c656420419f94e490a6aeb2f51e","9356b1fd50944ad79b79f164e72ac40c","96893e11a10149959294246b255862d8","f929fd25df6742afa80ceada1ab8f345","2b481b0548514e9d8bf745acc896361f","529758d5fcc74c05a5a5e837d4b336c9","06e3c95bfed14fe9a05e45a49d1419a1","f50146a937ce436988d9fb8157741336"]},"id":"_HeBphwClvhn","executionInfo":{"status":"ok","timestamp":1755310921692,"user_tz":-330,"elapsed":183901,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"321af2c7-11d6-4b13-e574-4fc3bcd48f94"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Function Name __init__\n","Function Name ToRunPipeline\n","Function Name Load_data_from_HF\n","Loading the train dataset from jpkarthikeyan/Tourism-visit-with-us-dataset\n","Shape of the train dataset: (3302, 19)\n","Shape of the train dataset: (826, 19)\n","--------------------------------------------------\n","Function Name Preprocessing_dataset\n","--------------------------------------------------\n","Function Name Building_Models\n","Model DecisionTreeClassifier started\n","Fitting 3 folds for each of 50 candidates, totalling 150 fits\n","model:Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisiting',\n","                                                   'MonthlyIncome']),\n","                                                 ('onehot',\n","                                                  OneHotEncoder(drop='first',\n","                                                                handle_unknown='ignore',\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 DecisionTreeClassifier(class_weight='balanced', max_depth=1,\n","                                        min_samples_leaf=2, min_samples_split=5,\n","                                        random_state=42, splitter='random'))])\n","best_score: 0.4412564666937607\n","best_params: {'classifier__splitter': 'random', 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': None, 'classifier__max_depth': 1, 'classifier__criterion': 'gini'}\n","Modle DecisionTreeClassifier completed\n","--------------------------------------------------\n","Model RandomForestClassifier started\n","Fitting 3 folds for each of 50 candidates, totalling 150 fits\n","model:Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisit...\n","                                                  OneHotEncoder(drop='first',\n","                                                                handle_unknown='ignore',\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 RandomForestClassifier(class_weight='balanced',\n","                                        criterion='entropy', max_depth=15,\n","                                        max_features=0.6, min_samples_leaf=7,\n","                                        min_samples_split=20, n_estimators=25,\n","                                        oob_score=True, random_state=42))])\n","best_score: 0.6512043836331847\n","best_params: {'classifier__oob_score': True, 'classifier__n_estimators': 25, 'classifier__min_samples_split': 20, 'classifier__min_samples_leaf': 7, 'classifier__max_features': 0.6, 'classifier__max_depth': 15, 'classifier__criterion': 'entropy', 'classifier__bootstrap': True}\n","Modle RandomForestClassifier completed\n","--------------------------------------------------\n","Model BaggingClassifier started\n","Fitting 3 folds for each of 50 candidates, totalling 150 fits\n","model:Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisit...\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 BaggingClassifier(estimator=DecisionTreeClassifier(class_weight='balanced',\n","                                                                    criterion='entropy',\n","                                                                    max_depth=9,\n","                                                                    min_samples_leaf=2,\n","                                                                    min_samples_split=12,\n","                                                                    random_state=42),\n","                                   max_features=0.5, max_samples=0.9,\n","                                   n_estimators=100, oob_score=True))])\n","best_score: 0.6453992143299877\n","best_params: {'classifier__oob_score': True, 'classifier__n_estimators': 100, 'classifier__max_samples': 0.9, 'classifier__max_features': 0.5, 'classifier__estimator__min_samples_split': 12, 'classifier__estimator__min_samples_leaf': 2, 'classifier__estimator__max_depth': 9, 'classifier__estimator__criterion': 'entropy'}\n","Modle BaggingClassifier completed\n","--------------------------------------------------\n","Model AdaBoostingClassifier started\n","Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 18 is smaller than n_iter=50. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n","27 fits failed out of a total of 54.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","27 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n","    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n","    estimator._validate_params()\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n","    validate_parameter_constraints(\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n","    raise InvalidParameterError(\n","sklearn.utils._param_validation.InvalidParameterError: The 'algorithm' parameter of AdaBoostClassifier must be a str among {'SAMME'}. Got 'SAMME.R' instead.\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.         0.         0.         0.         0.10068653 0.09769529\n"," 0.10326206 0.10878005 0.13623849        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan]\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["model:Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisiting',\n","                                                   'MonthlyIncome']),\n","                                                 ('onehot',\n","                                                  OneHotEncoder(drop='first',\n","                                                                handle_unknown='ignore',\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 AdaBoostClassifier(algorithm='SAMME', learning_rate=0.1,\n","                                    n_estimators=100, random_state=42))])\n","best_score: 0.13623849169640104\n","best_params: {'classifier__n_estimators': 100, 'classifier__learning_rate': 0.1, 'classifier__algorithm': 'SAMME'}\n","Modle AdaBoostingClassifier completed\n","--------------------------------------------------\n","Model GradientBoostingClassifier started\n","Fitting 3 folds for each of 50 candidates, totalling 150 fits\n","model:Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisiting',\n","                                                   'MonthlyIncome']),\n","                                                 ('onehot',\n","                                                  OneHotEncoder(drop='first',\n","                                                                handle_unknown='ignore',\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 GradientBoostingClassifier(learning_rate=0.5, max_depth=5,\n","                                            max_features='log2',\n","                                            random_state=42, subsample=0.8))])\n","best_score: 0.6906142009293693\n","best_params: {'classifier__subsample': 0.8, 'classifier__n_estimators': 100, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'log2', 'classifier__max_depth': 5, 'classifier__learning_rate': 0.5, 'classifier__criterion': 'friedman_mse'}\n","Modle GradientBoostingClassifier completed\n","--------------------------------------------------\n","Model XGBoostingClassifier started\n","Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [02:21:57] WARNING: /workspace/src/learner.cc:738: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  bst.update(dtrain, iteration=i, fobj=obj)\n"]},{"output_type":"stream","name":"stdout","text":["model:Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisit...\n","                               feature_types=None, feature_weights=None,\n","                               gamma=0, grow_policy=None, importance_type=None,\n","                               interaction_constraints=None, learning_rate=0.2,\n","                               max_bin=None, max_cat_threshold=None,\n","                               max_cat_to_onehot=None, max_delta_step=None,\n","                               max_depth=7, max_leaves=None,\n","                               min_child_weight=None, missing=nan,\n","                               monotone_constraints=None, multi_strategy=None,\n","                               n_estimators=np.int64(60), n_jobs=None,\n","                               num_parallel_tree=None, ...))])\n","best_score: 0.675510886513672\n","best_params: {'classifier__subsample': 1.0, 'classifier__reg_alpha': 2, 'classifier__n_estimators': np.int64(60), 'classifier__max_depth': 7, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0, 'classifier__colsample_bytree': 1.0}\n","Modle XGBoostingClassifier completed\n","--------------------------------------------------\n","--------------------------------------------------\n","{'DecisionTreeClassifier': {'model': Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisiting',\n","                                                   'MonthlyIncome']),\n","                                                 ('onehot',\n","                                                  OneHotEncoder(drop='first',\n","                                                                handle_unknown='ignore',\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 DecisionTreeClassifier(class_weight='balanced', max_depth=1,\n","                                        min_samples_leaf=2, min_samples_split=5,\n","                                        random_state=42, splitter='random'))]), 'best_score': np.float64(0.4412564666937607), 'best_params': {'classifier__splitter': 'random', 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': None, 'classifier__max_depth': 1, 'classifier__criterion': 'gini'}}, 'RandomForestClassifier': {'model': Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisit...\n","                                                  OneHotEncoder(drop='first',\n","                                                                handle_unknown='ignore',\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 RandomForestClassifier(class_weight='balanced',\n","                                        criterion='entropy', max_depth=15,\n","                                        max_features=0.6, min_samples_leaf=7,\n","                                        min_samples_split=20, n_estimators=25,\n","                                        oob_score=True, random_state=42))]), 'best_score': np.float64(0.6512043836331847), 'best_params': {'classifier__oob_score': True, 'classifier__n_estimators': 25, 'classifier__min_samples_split': 20, 'classifier__min_samples_leaf': 7, 'classifier__max_features': 0.6, 'classifier__max_depth': 15, 'classifier__criterion': 'entropy', 'classifier__bootstrap': True}}, 'BaggingClassifier': {'model': Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisit...\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 BaggingClassifier(estimator=DecisionTreeClassifier(class_weight='balanced',\n","                                                                    criterion='entropy',\n","                                                                    max_depth=9,\n","                                                                    min_samples_leaf=2,\n","                                                                    min_samples_split=12,\n","                                                                    random_state=42),\n","                                   max_features=0.5, max_samples=0.9,\n","                                   n_estimators=100, oob_score=True))]), 'best_score': np.float64(0.6453992143299877), 'best_params': {'classifier__oob_score': True, 'classifier__n_estimators': 100, 'classifier__max_samples': 0.9, 'classifier__max_features': 0.5, 'classifier__estimator__min_samples_split': 12, 'classifier__estimator__min_samples_leaf': 2, 'classifier__estimator__max_depth': 9, 'classifier__estimator__criterion': 'entropy'}}, 'AdaBoostingClassifier': {'model': Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisiting',\n","                                                   'MonthlyIncome']),\n","                                                 ('onehot',\n","                                                  OneHotEncoder(drop='first',\n","                                                                handle_unknown='ignore',\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 AdaBoostClassifier(algorithm='SAMME', learning_rate=0.1,\n","                                    n_estimators=100, random_state=42))]), 'best_score': np.float64(0.13623849169640104), 'best_params': {'classifier__n_estimators': 100, 'classifier__learning_rate': 0.1, 'classifier__algorithm': 'SAMME'}}, 'GradientBoostingClassifier': {'model': Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisiting',\n","                                                   'MonthlyIncome']),\n","                                                 ('onehot',\n","                                                  OneHotEncoder(drop='first',\n","                                                                handle_unknown='ignore',\n","                                                                sparse_output=False),\n","                                                  ['TypeofContact',\n","                                                   'Occupation', 'Gender',\n","                                                   'ProductPitched',\n","                                                   'MaritalStatus',\n","                                                   'Designation'])])),\n","                ('classifier',\n","                 GradientBoostingClassifier(learning_rate=0.5, max_depth=5,\n","                                            max_features='log2',\n","                                            random_state=42, subsample=0.8))]), 'best_score': np.float64(0.6906142009293693), 'best_params': {'classifier__subsample': 0.8, 'classifier__n_estimators': 100, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'log2', 'classifier__max_depth': 5, 'classifier__learning_rate': 0.5, 'classifier__criterion': 'friedman_mse'}}, 'XGBoostingClassifier': {'model': Pipeline(steps=[('preprocessor',\n","                 ColumnTransformer(transformers=[('num',\n","                                                  Pipeline(steps=[('imputer',\n","                                                                   SimpleImputer(strategy='median')),\n","                                                                  ('scaler',\n","                                                                   StandardScaler())]),\n","                                                  ['Age', 'CityTier',\n","                                                   'DurationOfPitch',\n","                                                   'NumberOfPersonVisiting',\n","                                                   'NumberOfFollowups',\n","                                                   'PreferredPropertyStar',\n","                                                   'NumberOfTrips', 'Passport',\n","                                                   'PitchSatisfactionScore',\n","                                                   'OwnCar',\n","                                                   'NumberOfChildrenVisit...\n","                               feature_types=None, feature_weights=None,\n","                               gamma=0, grow_policy=None, importance_type=None,\n","                               interaction_constraints=None, learning_rate=0.2,\n","                               max_bin=None, max_cat_threshold=None,\n","                               max_cat_to_onehot=None, max_delta_step=None,\n","                               max_depth=7, max_leaves=None,\n","                               min_child_weight=None, missing=nan,\n","                               monotone_constraints=None, multi_strategy=None,\n","                               n_estimators=np.int64(60), n_jobs=None,\n","                               num_parallel_tree=None, ...))]), 'best_score': np.float64(0.675510886513672), 'best_params': {'classifier__subsample': 1.0, 'classifier__reg_alpha': 2, 'classifier__n_estimators': np.int64(60), 'classifier__max_depth': 7, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0, 'classifier__colsample_bytree': 1.0}}}\n","Function Name Model_Evaluation\n","Predict proability shape DecisionTreeClassifier (826, 2)\n","best threshold: 0.7076288212958588\n","Predict proability shape RandomForestClassifier (826, 2)\n","best threshold: 0.43784253782494276\n","Predict proability shape BaggingClassifier (826, 2)\n","best threshold: 0.4477094853527532\n","Predict proability shape AdaBoostingClassifier (826, 2)\n","best threshold: 0.3196189229737486\n","Predict proability shape GradientBoostingClassifier (826, 2)\n","best threshold: 0.24867338889476726\n","Predict proability shape XGBoostingClassifier (826, 2)\n","best threshold: 0.3477764427661896\n","--------------------------------------------------\n","                        model  accuracy  precision    recall  f1_score\n","0      DecisionTreeClassifier  0.699758   0.326848  0.528302  0.403846\n","1      RandomForestClassifier  0.868039   0.625000  0.786164  0.696379\n","2           BaggingClassifier  0.863196   0.613861  0.779874  0.686981\n","3       AdaBoostingClassifier  0.803874   0.491525  0.547170  0.517857\n","4  GradientBoostingClassifier  0.917676   0.766082  0.823899  0.793939\n","5        XGBoostingClassifier  0.929782   0.843537  0.779874  0.810458\n","Function Name Register_BestModel_HF\n","Uploading the best model into Hugging face\n"]},{"output_type":"display_data","data":{"text/plain":["BestModel_XGBoostingClassifier.joblib:   0%|          | 0.00/272k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1010878b0b20487b825d45ddd2caf18e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Uploading the best threshold text file to HF\n","--------------------------------------------------\n","--------------------------------------------------\n","Success: BuildingModels.py Completed\n"]}]},{"cell_type":"markdown","source":["# 4. Hosting In Hugging Face Streamlit(Front End Implementation)"],"metadata":{"id":"-PWTuTZHusYj"}},{"cell_type":"code","source":["pip install streamlit"],"metadata":{"id":"IppdmKSyu3G-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755315056791,"user_tz":-330,"elapsed":10069,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"072d6803-eb14-47a4-eef0-45dabb16ff65"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.48.1-py3-none-any.whl.metadata (9.5 kB)\n","Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n","Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n","Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n","Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.0)\n","Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.1.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n","Downloading streamlit-1.48.1-py3-none-any.whl (9.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n","Successfully installed pydeck-0.9.1 streamlit-1.48.1 watchdog-6.0.0\n"]}]},{"cell_type":"code","source":["pip install dill"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxuPHSfw8SRx","executionInfo":{"status":"ok","timestamp":1755315266049,"user_tz":-330,"elapsed":10632,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"6355b0e6-31b3-402e-aac7-6939c43eb0a1"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (0.3.8)\n"]}]},{"cell_type":"code","source":["%%writefile Deployment/requirements.txt\n","pandas\n","numpy\n","scikit-learn\n","joblib\n","streamlit\n","huggingface_hub\n","xgboost\n","dill"],"metadata":{"id":"dW90Nwy5rQE2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755316983229,"user_tz":-330,"elapsed":47,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"ce60c16b-bf54-4c42-8202-dbfb5a940e94"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting Deployment/requirements.txt\n"]}]},{"cell_type":"code","source":["%%writefile Deployment/README.md\n","---\n","title: Visit With Us - Tourism package prediction\n","emoji: 🚩\n","colorFrom: blue\n","colorTo: green\n","sdk: docker\n","sdk_version: 3.9\n","app_file: app.py\n","app_type: streamlit\n","pinned: false\n","license: mit\n","---\n","The streamlit app predicts the customer will purchace the tourism package"],"metadata":{"id":"mrU_4ijQrl_v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755311055431,"user_tz":-330,"elapsed":51,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"12f18a33-1367-4117-f44e-1b4924f54d04"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing Deployment/README.md\n"]}]},{"cell_type":"code","source":["%%writefile Deployment/Dockerfile\n","# Use a minimal base image with Python 3.9 installed\n","FROM python:3.9-slim\n","\n","# Set the working directory inside the container to /app\n","WORKDIR /app\n","\n","# Copy all files from the current directory on the host to the container's /app directory\n","COPY . .\n","\n","# Install Python dependencies listed in requirements.txt\n","RUN pip install --no-cache-dir -r requirements.txt\n","RUN mkdir -p /tmp/hf_cache && chmod -R 777 /tmp/hf_cache\n","ENV HF_HOME=/tmp/hf_cache\n","ENV HUGGINGFACE_HUB_CACHE=/tmp/hf_cache\n","ENV PYTHONUNBUFFERED=1\n","\n","\n","EXPOSE 7860\n","\n","\n","# Define the command to run the Streamlit app on port \"7860\" and make it accessible externally\n","CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=7860\", \"--server.address=0.0.0.0\", \"--server.enableXsrfProtection=false\"]"],"metadata":{"id":"F96pJ8MK1jPj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755311060837,"user_tz":-330,"elapsed":34,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"3dc4d80a-c50f-458d-e6dc-535f4ebc9704"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing Deployment/Dockerfile\n"]}]},{"cell_type":"code","source":["%%writefile Deployment/app.py\n","import streamlit as st\n","import pandas as pd\n","import joblib\n","import os\n","import dill\n","import logging\n","from huggingface_hub import login,hf_hub_download\n","from xgboost import XGBClassifier\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)\n","cache_dir = \"/tmp/hf_cache\"\n","os.environ[\"HF_HOME\"] = cache_dir\n","os.environ[\"HUGGINGFACE_HUB_CACHE\"] = cache_dir\n","# base_path = os.getcwd()\n","# logger.info(f\"Base Path: {base_path}\")\n","# streamlit_config_dir = os.path.join(base_path,'.streamlit')\n","# os.makedirs(streamlit_config_dir,exist_ok=True)\n","# logger.info(f'streamlit_config_dir: {streamlit_config_dir}')\n","# os.environ['STREAMLIT_CONFIG_DIR'] = streamlit_config_dir\n","\n","# os.makedirs('/content/.streamlit', exist_ok=True)\n","# os.environ['STREAMLIT_CONFIG_DIR'] = '/content/.streamlit'\n","\n","try:\n","  hf_token = os.getenv(\"HUGGINGFACE_TOKEN\")\n","\n","  if hf_token:\n","    login(token=hf_token)\n","    logger.info(\"Successfully logged in to Hugging Face\")\n","  else:\n","    logger.error(\"Hugging face token not found\")\n","    st.error(\"Huggingface token not found\")\n","except Exception as ex:\n","  logger.error(f\"Failed to login to Hugging face: {ex} \")\n","  st.write(f\"Failed to login to Hugging face: {ex} \")\n","\n","try:\n","  os.makedirs(cache_dir, exist_ok=True)\n","  logger.info(f\"Created cache directory {cache_dir}\")\n","except Exception as ex:\n","  logger.error(f\"Failed to create cache directory {cache_dir}: {ex}\")\n","  st.error(f\"Failed to create cache directory {cache_dir}: {ex}\")\n","\n","\n","st.title(\"Visit with Us: Tourism Package Prediction\")\n","st.write(\"Enter the Customer details to predict the likehood of purchasing the tourism packages\")\n","\n","\n","if 'predictor' not in st.session_state:\n","  st.session_state.predictor = None\n","  st.session_state.model_loaded = False\n","\n","class PredictorTourism:\n","\n","  def __init__(self):\n","    self.Subfolders = 'Master'\n","    self.repoID = 'jpkarthikeyan/Tourism_Prediction_Model'\n","    self.model = None\n","    self.best_threshold = 0.0\n","\n","\n","  def Load_Model(self):\n","    try:\n","      logger.info(\"Loading best model\")\n","      model_path = hf_hub_download(\n","          repo_id = self.repoID,filename = f'Model_Dump_JOBLIB/BestModel_XGBoostingClassifier.joblib',\n","          repo_type = 'model')\n","      threshold_path = hf_hub_download(\n","          repo_id = self.repoID, filename=f'Model_Dump_JOBLIB/best_threshold.txt',\n","          repo_type='model')\n","\n","      logger.info(f\"Model path: {model_path}\")\n","      logger.info(f\"Threshold path:  {threshold_path}\")\n","\n","      #self.model = joblib.load(model_path)\n","      with open(model_path, 'rb') as f:\n","        self.model = joblib.load(f)\n","      with open(threshold_path,'r') as f:\n","        self.best_threshold = float(f.read())\n","      st.success(\"Model and threshold loaded successfully\")\n","      return True\n","\n","    except Exception as ex:\n","      st.error(f'Exception: {ex}')\n","      logging.error(f'Exception {ex}')\n","      return False\n","\n","\n","  def Predict(self, data):\n","    try:\n","      logger.info(f\"Input Data: {data}\")\n","      df= pd.DataFrame([data])\n","      logger.info(f\"Data shape: {df.shape}\")\n","      logger.info(f\"Dataframe columns: {df.columns.tolist()}\")\n","      prob = self.model.predict_proba(df)[:,1]\n","      prediction = int(prob >= self.best_threshold)\n","      return prediction\n","\n","    except Exception as ex:\n","      logger.error(f\"Exception in predict: {ex}\", exc_info=True)\n","      st.error(f\"Exception Prediction: {ex}\")\n","      return ex\n","\n","\n","if not st.session_state.model_loaded:\n","  st.session_state.predictor = PredictorTourism()\n","  st.session_state.model_loaded = st.session_state.predictor.Load_Model()\n","\n","with st.form(\"customer_form\"):\n","  st.header(\"Customer Details\")\n","  col1, col2,col3 = st.columns(3)\n","\n","  with col1:\n","\n","    age = st.number_input(\"Age\", min_value=18, max_value=100, value=41)\n","    gender = st.selectbox('Gender',['Male','Female'])\n","    MaritalStatus = st.selectbox('MaritalStatus',['Married','Unmarried','Single','Divorced'])\n","    Occupation = st.selectbox('Occupation',['Free Lancer','Salaried','Small Business','Large Business'])\n","    Designation = st.selectbox('Designation',['AVP','Manager','Executive','Senior Manager','VP'])\n","    MonthlyIncome = st.number_input('MonthlyIncome',min_value=0, max_value=1000000,value=20999)\n","\n","  with col2:\n","\n","    typeofcontact = st.selectbox(\"TypeofContact\",['Self Enquiry','Company Invited'])\n","    citytier = st.selectbox('citytier',[1,2,3], index=2)\n","    DurationOfPitch = st.number_input('DurationOfPitch', min_value=1, max_value=60, value=6)\n","    ProductPitched = st.selectbox('ProductPitched',['Deluxe','Basic','Standard','Super Deluxe','King'])\n","    PreferredPropertyStar = st.selectbox(\"'PreferredPropertyStar\",[3,2,1])\n","    NumberOfTrips = st.number_input('NumberOfTrips',min_value=0, max_value=30, value=1)\n","\n","\n","  with col3:\n","    NumberOfPersonVisiting = st.number_input('NumberOfPersonVisiting',min_value=1,max_value=10,value=3)\n","    NumberOfFollowups = st.number_input('NumberOfFollowups',min_value=0,max_value=10, value=3)\n","    NumberOfChildrenVisiting= st.number_input('NumberOfChildrenVisiting',min_value=0,max_value=5,value=0)\n","    Passport= st.selectbox('Passport',['Yes','No'],format_func=lambda x:\"Yes\" if x==\"Yes\" else \"No\")\n","    Owncar= st.selectbox('OwnCar',['Yes','No'],format_func=lambda x:\"Yes\" if x==\"Yes\" else \"No\")\n","    PitchSatisfactionScore= st.number_input('PitchSatisfactionScore',min_value=1,max_value=5,value=3)\n","\n","\n","  submitted = st.form_submit_button(\"Predict\")\n","\n","if submitted:\n","  input_data = {\n","      'Age':age,\n","      'TypeofContact':typeofcontact,\n","      'CityTier':citytier,\n","      'DurationOfPitch':DurationOfPitch,\n","      'Occupation':Occupation,\n","      'Gender':gender,\n","      'NumberOfPersonVisiting':NumberOfPersonVisiting,\n","      'NumberOfFollowups':NumberOfFollowups,\n","      'ProductPitched':ProductPitched,\n","      'PreferredPropertyStar':PreferredPropertyStar,\n","      'MaritalStatus':MaritalStatus,\n","      'NumberOfTrips':NumberOfTrips,\n","      'Passport':1 if Passport ==\"Yes\" else 0,\n","      'OwnCar':1 if Owncar ==\"Yes\" else 0,\n","      'PitchSatisfactionScore':PitchSatisfactionScore,\n","      'NumberOfChildrenVisiting':NumberOfChildrenVisiting,\n","      'Designation':Designation,\n","      'MonthlyIncome':MonthlyIncome\n","\n","  }\n","\n","\n","  if st.session_state.predictor:\n","    result = st.session_state.predictor.Predict(input_data)\n","\n","    if result is not None:\n","      st.subheader(f\"Prediction Result is {result}\")\n","      st.write(f\"Likely to purchase\" if result ==1 else \"Unlikely to purchase\")\n","    else:\n","      st.write(result)\n","      st.error(\"Error in prediction\")\n","  else:\n","    st.error(\"Models are not loaded, please ensure the model and threshold are available on Hugging face\")\n","\n"],"metadata":{"id":"MgAoOlhJvV_l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755317706563,"user_tz":-330,"elapsed":26,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"cf3f80ab-1efd-4eb5-d5aa-c9cfa9e7788b"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting Deployment/app.py\n"]}]},{"cell_type":"code","source":["#@title HostingInHuggingFace.py\n","%%writefile HostingInHuggingFace.py\n","import os\n","import inspect\n","import traceback\n","from huggingface_hub import HfApi, create_repo, login,hf_hub_download\n","from huggingface_hub.utils import RepositoryNotFoundError\n","\n","class HostingInHuggingFace:\n","  def __init__(self,base_path,hf_token=None):\n","    self.base_path = base_path\n","    self.hf_token = hf_token\n","    self.repo_id = 'jpkarthikeyan/Tourism-Prediction-Model-Space'\n","\n","  def CreatingSpaceInHF(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    api = HfApi()\n","    try:\n","      print(f\"Checking for {self.repo_id} is correct or not\")\n","      api.repo_info(repo_id = self.repo_id,\n","                    repo_type='space',\n","                    token = self.hf_token)\n","      print(f\"Space {self.repo_id} already exists\")\n","    except RepositoryNotFoundError:\n","      create_repo(repo_id=self.repo_id,\n","                  repo_type='space',\n","                  space_sdk='docker',\n","                  private=False,\n","                  token=self.hf_token)\n","      print(f\"Space created in {self.repo_id}\")\n","    except Exception as ex:\n","      print(f\"Exception in creating space {ex}\")\n","      traceback.print_exc()\n","    finally:\n","      print('-'*50)\n","\n","\n","  def UploadDeploymentFile(self):\n","    print(f\"Function Name {inspect.currentframe().f_code.co_name}\")\n","    try:\n","      api = HfApi(token=self.hf_token)\n","      directory_to_upload = os.path.join(self.base_path,'Deployment')\n","      print(f\"Directory to upload {directory_to_upload} into HF Space {self.repo_id}\")\n","      api.upload_folder(repo_id=self.repo_id, folder_path=directory_to_upload,\n","                        repo_type='space')\n","      print(f\"Successfully upload {directory_to_upload} into {self.repo_id}\")\n","      return True\n","    except Exception as ex:\n","      print(f\"Exception occured {ex}\")\n","      print(traceback.print_exc())\n","      return False\n","    finally:\n","      print('-'*50)\n","\n","  def ToRunPipeline(self):\n","    try:\n","      self.CreatingSpaceInHF()\n","      if self.UploadDeploymentFile():\n","        print('Deployment pipeline completed')\n","        return True\n","      else:\n","        print('Deployment pipeline failed')\n","        return False\n","    except Exception as ex:\n","      print(f\"Exception occured {ex}\")\n","      print(traceback.print_exc())\n","      return False\n","    finally:\n","      print('-'*50)\n"],"metadata":{"id":"x_puqsQWuv-C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755320007548,"user_tz":-330,"elapsed":46,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"7d84a3f5-123d-4c29-fc2f-62ff65210e98"},"execution_count":102,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting HostingInHuggingFace.py\n"]}]},{"cell_type":"code","source":["ObjHostingInHF = HostingInHuggingFace(base_path,hf_token)\n","if ObjHostingInHF.ToRunPipeline():\n","  print('Success: HostingInHuggingFace.py Completed')\n","else:\n","  print('Exception: HostingInHuggingFace.py failed')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fd90h_63slEP","executionInfo":{"status":"ok","timestamp":1755317731328,"user_tz":-330,"elapsed":1487,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"1cac7f8c-da87-486d-b71c-dc83ebd679b5"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["Function Name CreatingSpaceInHF\n","Checking for jpkarthikeyan/Tourism-Prediction-Model-Space is correct or not\n","Space jpkarthikeyan/Tourism-Prediction-Model-Space already exists\n","--------------------------------------------------\n","Function Name UploadDeploymentFile\n","Directory to upload /content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master/Deployment into HF Space jpkarthikeyan/Tourism-Prediction-Model-Space\n","Successfully upload /content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master/Deployment into jpkarthikeyan/Tourism-Prediction-Model-Space\n","--------------------------------------------------\n","Deployment pipeline completed\n","--------------------------------------------------\n","Success: HostingInHuggingFace.py Completed\n"]}]},{"cell_type":"markdown","source":["# Main Function"],"metadata":{"id":"VmVIs57DX9vR"}},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master/'"],"metadata":{"id":"DvSDjubyxhGL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755277451938,"user_tz":-330,"elapsed":60,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"12c869e6-cdd0-4ccd-ef84-61568ab39660"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/Master\n"]}]},{"cell_type":"code","source":["%%writefile main.py\n","import os\n","import sys\n","import argparse\n","import logging\n","import traceback\n","from huggingface_hub import HfApi\n","from dotenv import load_dotenv\n","\n","\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', filename='pipeline.log')\n","base_path = os.path.abspath(os.path.join(os.path.dirname(__file__),'..','Master'))\n","hf_token = os.getenv('HF_TOKEN')\n","\n","logging.info(f\"Base Path {base_path}\")\n","sys.path.append(base_path)\n","\n","if not hf_token:\n","  logging.error(\"HF_TOKEN not found\")\n","  sys.exit(1)\n","\n","api = HfApi(token = hf_token)\n","try:\n","  user = api.whoami()\n","  logging.error(f\"Authenticated as :{user['name']}\")\n","except Exception as ex:\n","  logging.error(f\"TokenError: {ex}\")\n","  sys.exit(1)\n","\n","\n","parser = argparse.ArgumentParser(description = 'To Run a specific job in a pipileine')\n","parser.add_argument('--job', type=str, required=True, choices=['register','prepare','modelbuilding','deploy'], help ='Job to execute: register, prepare, modelbuilding and deploy in hugging face')\n","\n","args = parser.parse_args()\n","\n","data_dir = os.path.join(base_path,'Data')\n","logging.info(f\"data_dir: {data_dir}\")\n","if os.path.exists(data_dir):\n","  os.makedirs(data_dir, exist_ok=True)\n","\n","model_dir = os.path.join(base_path,'Model_Dump_JOBLIB')\n","logging.info(f\"model_dir: {model_dir}\")\n","if os.path.exists(model_dir):\n","  os.makedirs(model_dir, exist_ok=True)\n","\n","if args.job == 'register':\n","  from DataRegistration import DataRegistration\n","  ObjDataReg = DataRegistration(base_path,hf_token)\n","  if not ObjDataReg.ToRunPipeline():\n","    logging.error(\"DataRegistration failed\")\n","    sys.exit(1)\n","  else:\n","    logging.info(\"DataRegistration completed in Hugging Face\")\n","\n","if args.job == 'prepare':\n","  from DataPrepration import DataPrepration\n","  ObjDataprep = DataPrepration(base_path,hf_token)\n","  if not ObjDataprep.ToRunPipeline():\n","    logging.error(\"Data Registration failed\")\n","    sys.exit(1)\n","  else:\n","    logging.info(\"Data prepration completed\")\n","\n","if args.job == 'modelbuilding':\n","  from ModelBuilding import BuildingModels\n","  ObjModelBuild = BuildingModels(base_path, hf_token)\n","  if not ObjModelBuild.ToRunPipeline():\n","    logging.error(\"Model Building failed\")\n","    sys.exit(1)\n","  else:\n","    logging.info(\"Model Building Completed\")\n","\n","\n","\n","\n","\n"],"metadata":{"id":"9Sx49q1ym8FF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755277453556,"user_tz":-330,"elapsed":37,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"81582d43-b6a3-48af-ad12-680777ffbf55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting main.py\n"]}]},{"cell_type":"markdown","source":["# pipeline.yml"],"metadata":{"id":"2XBCf10RzakL"}},{"cell_type":"code","source":["%cd '/content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RC13l7HATg8x","executionInfo":{"status":"ok","timestamp":1755277578547,"user_tz":-330,"elapsed":76,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"828518a8-6f6f-40c2-81c2-59e1c0bc5f72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/PGP_AI_ML_GREAT_LEARNING/10_Advance_Machine_Learning_And_MLOps/Final_Project/VisitWithUs-Tourism_version_1_1\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvpBtUiUTiuF","executionInfo":{"status":"ok","timestamp":1755274157990,"user_tz":-330,"elapsed":169,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"681ece8b-e5b9-4550-d0b8-e88c375b73f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Master\n"]}]},{"cell_type":"code","source":["%%writefile .github/workflows/pipeline.yml\n","name: VISIT WITH US TOURISM PREDICTION PIPELINE\n","on:\n","  push:\n","    branches:\n","      - main\n","    paths:\n","      - 'Master/Deployment/**'\n","      - 'Master/Data/tourism.csv'\n","      - 'Master/main.py'\n","      - 'Master/DataRegistration.py'\n","      - 'Master/DataPrepration.py'\n","      - 'Master/ModelBuilding.py'\n","      - 'Master/HostingInHuggingFace.py'\n","      - '.github/workflows/pipeline.yml'\n","  workflow_dispatch:\n","\n","jobs:\n","  data_registration:\n","    runs-on: ubuntu-latest\n","    steps:\n","      - name: Checkout Repository\n","        uses: actions/checkout@v4\n","\n","      - name: Set up Python\n","        uses: actions/setup-python@v4\n","        with:\n","          python-version: '3.12'\n","\n","      - name: Install Dependencies\n","        run: |\n","          python -m pip install --upgrade pip\n","          pip install huggingface_hub python-dotenv pandas\n","\n","      - name: List Direcory contents(debug)\n","        run: |\n","          ls -la . || echo \"Root Directory Contents\"\n","          ls -la Master/Data/ || echo \"Master/Data/ Directory not found\"\n","          ls -la Master/ || echo \"Master Directory\"\n","\n","      - name: Copy Dataset File\n","        env:\n","          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n","        run: |\n","          mkdir -p Master/Data\n","          if [ -f Master/Data/tourism.csv ]; then\n","            echo \"tourism.csv found in Master/Data\"\n","          else\n","            echo \"tourism.csv not found in Master/Data/\"\n","          fi\n","\n","      - name: Run DataRegistration.py\n","        env:\n","          HF_TOKEN: ${{ secrets.HF_TOKEN}}\n","        run: |\n","          if [ -d Master ]; then\n","            cd Master/\n","            python main.py --job register\n","          else\n","            echo \"Master Directory not found\"\n","            exit 1\n","          fi\n","\n","\n","      - name: Check Pipeline Status\n","        if: failure()\n","        run: |\n","          echo \"DataRegistration pipeline failed. please check logs\"\n","          exit 1\n","\n","      - name: Verify Upload\n","        env:\n","          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n","        run: |\n","          echo \"Verifying Upload on Hugging Face\"\n","          python -c \"import os; from huggingface_hub import HfApi; api=HfApi(token=os.getenv('HF_TOKEN'));print(api.repo_info(repo_id='jpkarthikeyan/Tourism-Visit-With-us-dataset',repo_type='dataset))\""],"metadata":{"id":"WjL8ua--5jUx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1755278976257,"user_tz":-330,"elapsed":64,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"58ddfa8a-52f9-4584-cdd3-7cfcf2eab018"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting .github/workflows/pipeline.yml\n"]}]},{"cell_type":"code","source":["!ls -R\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQz5qHd3s1xX","executionInfo":{"status":"ok","timestamp":1755278537741,"user_tz":-330,"elapsed":129,"user":{"displayName":"Karthikeyan JP","userId":"08094035270994931409"}},"outputId":"d51d6383-c80e-40e2-d341-3a7a0e81ff47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[".:\n","Master\n","\n","./Master:\n","BuildingModels.py\t main.py\n","Data\t\t\t Model_Dump_JOBLIB\n","DataPrepration.py\t __pycache__\n","DataRegistration.py\t README.md\n","Deployment\t\t Visit-With-Us-Tourism-Prediction_v1_1.ipynb\n","HostingInHuggingFace.py\n","\n","./Master/Data:\n","tourism.csv  train.csv\n","\n","./Master/Deployment:\n","\n","./Master/Model_Dump_JOBLIB:\n","\n","./Master/__pycache__:\n","DataRegistration.cpython-311.pyc\n"]}]}]}